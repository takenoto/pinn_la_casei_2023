Aumentei neurons, layers E DOMAIN + TEST!!!!

Starting Numerical Methods
Pinn best index = 0
Pinn best error = 8.970179557800293

-------------------------------


        def iterate_cstr_convergence(
    eq_params, process_params
):
    
    dictionary = {
        '60x4 swish':{
            'layer_size': [1] + [60] * 4 + [4],
            'activation':'swish',
            'initializer': 'Glorot uniform'
        },
        '60x4 tanh':{
            'layer_size': [1] + [60] * 4 + [4],
            'activation':'tanh',
            'initializer': 'Glorot uniform'
        },
        # '32x3 glorot':{
        #     'layer_size': [1] + [16] * 3 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # '32x4 glorot':{
        #     'layer_size': [1] + [16] * 4 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # '32x5 glorot':{
        #     'layer_size': [1] + [16] * 5 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # '32x6 glorot':{
        #     'layer_size': [1] + [16] * 6 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # 'cstr-5':{
        #     'layer_size': [1] + [32] * 5 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # 'cstr-6':{
        #     'layer_size': [1] + [12] * 2 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # 'cstr-7':{
        #     'layer_size': [1] + [12] * 3 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
        # 'cstr-8':{
        #     'layer_size': [1] + [12] * 4 + [4],
        #     'activation':'tanh',
        #     'initializer': 'Glorot uniform'
        # },
    }

    for key in dictionary:
        dictionary[key]["adam_epochs"] = 22000 #15000 # 80000 #default_adam_epochs
        dictionary[key]["num_domain"] = 1500 #2000
        dictionary[key]["num_test"] = 3000 #2000
        dictionary[key]["lbfgs_pre"] = False #True
        dictionary[key]["lbfgs_post"] = True
        # dictionary[key]['t_s'] = process_params.t_final
        # dictionary[key]['w_X'] = 3
        # dictionary[key]['w_V'] = 3
        # dictionary[key]['V_s']= process_params.max_reactor_volume,
        # dictionary[key]['X_s']= eq_params.Xo,
        # dictionary[key]['P_s']= eq_params.Po,
        # dictionary[key]['S_s']= eq_params.So,

-------------------------

RUN CSTR NEW CONVERGENCE TEST (RELU + LAYERS)
Compiling model...
Building feed-forward neural network...
C:\Python39\lib\site-packages\deepxde\nn\tensorflow_compat_v1\fnn.py:114: UserWarning: `tf.layers.dense` is deprecated and 
will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  return tf.layers.dense(
'build' took 0.084148 s

2023-03-10 07:26:48.212849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
'compile' took 1.915908 s

Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.
Initializing variables...
2023-03-10 07:26:50.082504: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled
Training model...

Step      Train loss                                                                          Test loss
                                                       Test metric
0         [2.22e+02, 1.55e+03, 1.80e+03, 7.85e-01, 1.32e+00, 3.60e+01, 4.58e+02, 1.00e+00]    [2.15e+02, 1.51e+03, 1.74e+03, 7.87e-01, 1.32e+00, 3.60e+01, 4.58e+02, 1.00e+00]    []
15000     [5.19e-02, 6.69e-02, 4.70e-01, 4.23e-01, 1.92e-04, 8.35e-07, 1.57e-04, 1.34e+00]    [5.01e-02, 9.31e-02, 4.73e-01, 4.06e-01, 1.92e-04, 8.35e-07, 1.57e-04, 1.34e+00]    []
22000     [3.40e-02, 2.50e-02, 8.90e-02, 2.07e-01, 2.04e-04, 7.41e-07, 1.30e-04, 1.20e+00]    [2.53e-01, 2.46e+00, 6.19e+00, 4.41e-01, 2.04e-04, 7.41e-07, 1.30e-04, 1.20e+00]    []

Best model at step 22000:
  train loss: 1.55e+00
  test loss: 1.05e+01
  test metric: []

'train' took 665.861502 s

Compiling model...
'compile' took 1.290103 s

Training model...

Step      Train loss                                                                          Test loss
                                                       Test metric
22000     [3.40e-02, 2.50e-02, 8.90e-02, 2.07e-01, 2.04e-04, 7.41e-07, 1.30e-04, 1.20e+00]    [2.53e-01, 2.46e+00, 6.19e+00, 4.41e-01, 2.04e-04, 7.41e-07, 1.30e-04, 1.20e+00]    []
23000     [2.68e-02, 1.10e-02, 6.86e-02, 1.47e-01, 8.52e-05, 3.80e-08, 3.78e-05, 1.16e+00]    [2.68e-02, 1.10e-02, 6.86e-02, 1.47e-01, 8.52e-05, 3.80e-08, 3.78e-05, 1.16e+00]
24000     [3.02e-02, 1.03e-02, 3.49e-02, 1.32e-01, 1.37e-04, 4.75e-07, 6.05e-05, 1.14e+00]    [3.02e-02, 1.03e-02, 3.49e-02, 1.32e-01, 1.37e-04, 4.75e-07, 6.05e-05, 1.14e+00]
25000     [3.17e-02, 5.79e-03, 2.99e-02, 1.15e-01, 1.25e-04, 1.13e-06, 2.86e-05, 1.13e+00]    [3.17e-02, 5.79e-03, 2.99e-02, 1.15e-01, 1.25e-04, 1.13e-06, 2.86e-05, 1.13e+00]
26000     [2.68e-02, 5.04e-03, 2.41e-02, 1.11e-01, 1.65e-04, 2.22e-07, 5.68e-05, 1.12e+00]    [2.68e-02, 5.04e-03, 2.41e-02, 1.11e-01, 1.65e-04, 2.22e-07, 5.68e-05, 1.12e+00]
26059     [2.69e-02, 4.99e-03, 2.38e-02, 1.11e-01, 1.49e-04, 1.07e-06, 7.31e-05, 1.12e+00]    [1.99e-01, 2.40e+00, 4.50e+00, 7.55e-01, 1.49e-04, 1.07e-06, 7.31e-05, 1.12e+00]    []

Best model at step 26059:
  train loss: 1.28e+00
  test loss: 8.97e+00
  test metric: []

'train' took 202.611799 s

Compiling model...
Building feed-forward neural network...
'build' took 0.078188 s

'compile' took 1.329088 s

Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.
Initializing variables...
Training model...

Step      Train loss                                                                          Test loss
                                                       Test metric
0         [1.31e+00, 3.59e+01, 4.59e+02, 1.00e+00, 1.32e+00, 3.60e+01, 4.58e+02, 1.00e+00]    [1.31e+00, 3.59e+01, 4.59e+02, 1.00e+00, 1.32e+00, 3.60e+01, 4.58e+02, 1.00e+00]    []
15000     [1.93e-02, 3.93e-04, 1.62e-04, 2.66e-03, 4.01e-05, 2.91e-05, 9.57e-07, 4.09e-05]    [3.15e+00, 7.26e+01, 1.17e+02, 4.75e-01, 4.01e-05, 2.91e-05, 9.57e-07, 4.09e-05]    []
22000     [5.27e-05, 3.89e-06, 1.28e-05, 8.56e-06, 5.08e-10, 8.12e-09, 1.00e-07, 7.10e-10]    [7.79e-01, 2.91e+01, 4.95e+01, 1.97e-01, 5.08e-10, 8.12e-09, 1.00e-07, 7.10e-10]    []

Best model at step 22000:
  train loss: 7.80e-05
  test loss: 7.95e+01
  test metric: []

'train' took 360.275557 s

Compiling model...
'compile' took 1.072058 s

Training model...

Step      Train loss                                                                          Test loss
                                                       Test metric
22000     [5.27e-05, 3.89e-06, 1.28e-05, 8.56e-06, 5.08e-10, 8.12e-09, 1.00e-07, 7.10e-10]    [7.79e-01, 2.91e+01, 4.95e+01, 1.97e-01, 5.08e-10, 8.12e-09, 1.00e-07, 7.10e-10]    []
22052     [5.26e-05, 3.68e-06, 5.00e-06, 8.60e-06, 3.87e-10, 9.09e-11, 1.46e-09, 1.54e-10]    [7.79e-01, 2.91e+01, 4.95e+01, 1.97e-01, 3.87e-10, 9.09e-11, 1.46e-09, 1.54e-10]    []

Best model at step 22052:
  train loss: 6.99e-05
  test loss: 7.95e+01
  test metric: []

'train' took 2.474653 s

-------------------------

