# Log

## Testes a se fazer

- FED-BATCH
  - Novo tempo de simula√ß√£o, menor...
- CSTR
  - As melhores redes do batch...
  - Loss v4 com os 3 nondims tanh 60k adam
  - Tentar scaler 1/10 pra todos mas 1 pro volume. 10 pro tempo vai cancelar ent√£o tb daria certo...
  - SGD x Adam e tanh x swish
- Tente abrir as redes que deram flat. Tacou um bias? Imagino que se valores ficarem entre 0 e 1 ele possa tb estar ignorando muitos dos bias, zerando, ou o contr√°rio, ignorando os inputs. Isso √© uma info legal embora eu n√£o saiba bem interpretar ela.


## Anota√ß√µes
- Loss v4
  - Batch
    - J√° fiz v√°rios nd com t e sem t e linear e vi que muitos ficam ok.; A loss v4 parece estimular o volume a ficar caindo e n√£o oscilando.
    - None e Desvio validados! Desvio n√£o ficou t√£o bom mas pode ter a ver com a minha escolha de scaler pras vari√°veis.
    - Batch
      - scaler 1/10 pra tudo pareceu melhorar resultados nondim linear
  - Adimensionaliza√ß√£o + scaling pra deixar todo mundo entre 0 e 10 parece a melhor op√ß√£o at√© agora. Excluindo sempre o tempo da adimensionaliza√ß√£o, claro... Ser√° que fica bom entre 0 e 10 justamente por ser o mesmo range de varia√ß√£o de t_final? Que vai at√© 10.2...
  - √â, mas tamb√©m foi o √∫nico em que eu botei pra ir at√© 55k otimiza√ß√£o. Isso deve contar mais que todo o resto zzzzzzzz.... Os outros eram s√≥ 35k eu acho.


## by date

### 2024-02-19

- Iniciar corre√ß√µes da metodologia no arquivo.

### 2024-01-28

- TTODO

### 2024-01-22

- Rodar o CR t9F1d0 mas variando o npoints ao inv√©s de LR e redes. Faz v√°rios npoins pra 30x3 e 40x4.
  - p(8, 8, 8)
  - p(3, 32, 32)
  - p(8, 32, 32)
  - p(8, 300, 300)
  - p(300, 300, 300)
  - p(8, 1200, 1200)
- Fazer dados para obter rede somente para a cin√©tica (n√£o tem V como output e V=1!) para 30x3 e 40x4 variando LR
  - t9F1d0 n√£o pode porque Fin precisa ser != 0
  - t7F1d0 e t1 sem nondim 52.624265469999955 min
  - t1F1d0 e t1F1x10  84.85971691000013 min
  - t8 e t6 F1d10 66.99975563499999 min
- [EM PROGRESSO] Ilustra√ß√µes para metodologia
- TODO faz gr√°fico com imshow => pontos inicias vs pontos testes e treino vs erro
- TODO a conclus√£o parece que ser√° a mesma de antes: usar nondim viabiliza uma quantidade maior de redes e de LRs, ent√£o supostamente ficaria mais f√°cil encontrar um bom conjunto de hiperpar√¢metros simplesmente porque existem mais possibilidades. Algumas redes sem nondim ficam at√© boas, mas as "do lado" variando s√≥ um pouco LR, HL ou NL j√° ficam p√©ssimas ou d√£o aquela solu√ß√£o zerada que √© ainda pior que uma solu√ß√£o trivial, porque a solu√ß√£o trivial pelo menos √© v√°lida.

### 2024-01-18 + 2024-01-19 + 2024-01-21

- TODO rodar pra p8-32-32, pra montar gr√°ficos: (deixei redes NL40 e 30 reservadas pros testes prim√°rios e fim)
  - Rodar tempos:
      - t1-1 (sem nondim) pra comparar a performance em redes min√∫sculas : 118.554348555 min
      - t9 132.62632637333328 min
        - OK uma vez pro wAutic, pra poder plotar os 2 e comparar
        - TODO uma vez pro wA1
      - t8 ~ 112.72365334333332 min
      - t7 ~ 117.15610333333328 min
      - t6 ~ 146.886468555 min
  - t9F1d10 para alta vaz√£o e 0-50pa para ver se funciona com mais tempo || t~95.40187755666666 min
  - [ABANDONADO] t9F1d10 para o reator de baixa vaz√£o e 0-25pa pra ver se presta
    - NL: 4, 10, 20, 35, 60, 80,
    - HL: 2, 3, 4, 5, 6, 8
    - LR: 1e-3, que foi a do menor erro: "Lin-t9-F1d10 Lin-t9-F1d1040x4 tanh L7B LR-E-3_1 wautic-e2 Lin-Lin p8-32-32 45kep lbfgs-0-1 m2000 ic-2k"
    - wautic-e2
    - F1d10
    - 0-25pa
    - tempos: t9 (menor erro em um caso), t8, t7 e t6. T√° uma domin√¢ncia BEM √ìBVIA desses 4 tempos. valores de t_nondim aproximado:
      - t6 = 3.77
      - t7 = 12.04
      - t8 = 18.87
      - t9 = 10.0

### 2024-01-17

- üÜó pegar mais resultados ainda pra rede 30x3 e 40x4: com t2~t7 e F1d10, pra validar adimensionalia√ß√£o do tempo.

### 2024-01-16

- üÜó Fazer um com vaz√£o mais alta (5e-2 L/s) pra ver como fica. De repente tanto √© melhor enquanto processo quanto mais f√°cil de resolver. 
  - Ficou bom
- üÜó 0-15pa j√° sei que presta, voutestar agora 0-25
  - Pronto! 0-25 ficou perfeito! Basta simplesmente ver os que se saem melhores e acabou.
  - Rodei nessa ordem: Loop de fora nondim, loop interno n pontos (p8-32-32 etc). J√° roda tudo com A1 x autic2 pra comparar tamb√©m. Deu 36 por rede. S√≥ vou fazer a rede 30x3 por enquanto mesmo.
    - nondims: 1 por vez, na ordem que est√£o. t8 demorou ~70 min. t1 demorou 78min, mas j√° estava assistindo. t9F1 72 min. t9F1d10 69 minutos e ficou MUITO bom.
      - N¬∫ pontos, 1 por vez, na ordem em que est√£o.
  - OBS: sem nondim j√° pareceu ter ficado significativamente melhor
    - t1 => a 40x4 tem um autic vs A1 que fica bem melhor no autic.
  - A√≠ depois disso pegar os 2 melhores LRs, o melhor entreu autic e A1, e simplesmente faz v√°rias redes pra ter um gr√°fico. Pode ser no p8-32-32 pra ser mais r√°pido.

### 2024-01-15

- OK ler v√°rios dados no plot_caller a partir de uma pasta e agrupar eles. Eu basicamente copio os json da pasta do batch ou algo do g√™nero.
- OK agrupar dados
- Fiz alguns testes com o modelo sugerido pela Luciana (sem Xin, com X0) e ele tamb√©m ficou bem ruim. Ent√£oa o inv√©s de tentar tanta marmota vou aumentar os pontos e tentar achar um que preste.


### 2024-01-14

- Consegui implementar um imshow, j√° com exemplos e funcionando. J√° vai funcionar bem pro que queria. Agora √© testar e ver se fica leg√≠vel com os dados que tenho.

### 2024-01-10 

- Reler c√≥digo de plot_3D e plot_caller pra me familiarizar novamente com o que precisava ser feito.
- fazer um heatmap? Acho que √© mais f√°cil fazer por fora mesmo n√£o? Sei l√°

### 2023-11-28

- Rever c√≥digo da plotagem de gr√°fico...

### 2023-10-25

- TODO separar TODOs anteriores e ou deleta ou faz deleta fim
- TODO faz pelo menos um gr√°fico 3D pra ver se minha ideia original funcionou...
- TODO tenho que fazer √© um heatmap zzzz
- TODO ver escopo do trabalho e j√° deixa uma lista com NL e HL que foram testados, e afins, pra comparar nesse heatmap j√° sabendo o que ser√°.

### 2023-10-19

- disregard_previous_best=True no solver adam
- testes modifica√ß√£o equa√ß√£o de balan√ßo dNdt no PINN
- Erro num√©rico: dXdt estava apenas dX, n√£o dividia por dt...
- Fiz o teste de calcular como se fosse em mols a varia√ß√£o, n√£o funcionou
- N√£o estou sabendo incluir o efeito de dilui√ß√£o
- FEITO:: troca tudo e conc pra n√∫mero de moles
  - ODE preparer
  - run_reactor
  - loss v7
  - Do jeito que fiz a conc. vai estar sempre errado em V=0 (ali√°s, em V < V_threshold)... Porque to pegando o n√∫mero de moles e a√≠ vai pro infinito...
  - nesse ritmo vou ter que trocar a adimensionaliza√ß√£o porque s√£o valores em concentra√ß√£o... E n√£o faz sentido essa "adimensionaliza√ß√£o". Talvez eu precise fazer o que?
  - o grande problema √© que, mesmo que n√£o acontecesse nada, s√≥ a dilui√ß√£o deveria ser contada j√°. E n√£o vejo ela aparecendo em nenhum canto. Ent√£o n√£o tem como o efeito dela ser contado...
  -  desfaz tudo isso a√≠ e faz o efeito de dilui√ß√£o, que √© o que t√° faltando...
- FIXED: O equacionamento do PINN n√£o estava contabilizando o efeito da dilui√ß√£o:
  - previous: dNdt_calc = rN + (f_in * inletN - f_out * concN) / V_th
  - current: dNdt_calc = (f_in-f_out)*concN/V_th  + rN + (f_in * inletN - f_out * concN) / V_th
- Fiz pra varia√ß√£o de volume com v√°rios pontos de treino diferentes e em todos ficou volume bom e querendo zerar X, de novo, pra zerar a loss mais facilmente.
  - V√°rios pontos 8-32-32, 20-300-300 e 40-1200-1200 e todas deram errado.
  - Mudei camadas tamb√©m e n√£o deu em nada. Ent√£o pelo visto tenho que ir por outro caminho.
  - O problema continua sendo essa tend√™ncia infeliz em zerar o X.

- Todos s√≥ 0-50pa:
  - Cada um desses testes faz pro CR que j√° inicia no m√°ximo e na curva suave:
    - Lin-Lin-t1-1, Lin-Lin-t2-F1, Lin-Lin-t2-F1d10
    - Depois UPx1 F1d10 de t3 a t9
    - Da√≠ j√° devo saber se uma dessas formas de nondim √© melhor que as demais comparando, por exemplo, o perfil que ultrapassa a regi√£o de treino.
  - TODO: veja se pro cstr sem varia√ß√£o de volume, cont√≠nuo do in√≠cio ao fim, ele fica correto...
      - E com Xo e Xin = 0
  - Xo e Xin normais (Xin sempre √© 0 mas enfim)

# TODO ficaram faltando esses dois 2 a√≠: pro XPS do batch
        ("t1", "1", "Lin", "Lin"),
        ("t2", "F1", "Lin", "Lin"),
        ("t2", "F1d10", "Lin", "Lin"),
        em (8, 6),
            (30, 3),


# De verdade, antes de come√ßar, organize os dos dias anteriores. J√° t√° gigantesco.

Testes: (obs: todos foram feitos enquanto mexi no pc, ent√£o train_time e pred_time n√£o deve ser levados em conta)
1) TODO testar 3 varia√ß√µes de L7 em 4 tipos de reator (tudo padr√£o, tanh, etc), sem nondim, rede 10x3, LR1e-3:
  - OBS: todas as redes 10x3, e s√≥ com tanh, pontos 20-20-20. Depois olho outras redes e afins. J√° sei que a 10x3 presta ent√£o vamo nela. Veja que s√£o muitas varia√ß√µes de L7 ent√£o demora MUITOOOOOOOOO nem vale a pena. Ent√£o vou fazer s√≥ a 7G.
  - Rever: Olha, acho que a ordem de testes de nondim deve ser impacto do t => impacto de F1 e d10 e x10 j√° nos melhores ts sinceramente, poupa muito trabalho
  1¬∫ Roda os LINLIN LINUPX1  e No nodim simples
  2¬∫ roda os testes que exploram todo o tempo??
  - 1.1) TODO- Rede t => XPS :: Foi uma p√©ssima ideia rodar tudo junto. Demorando demais, vai terminar nunca zzzz... A mem√≥ria continua se acumulando por causa do python, mesmo com tudo mds. Chegou a 91% de mem√≥ria em 200 itera√ß√µes ainda do primeiro batch, o segundo nem ia conseguir rodar. Deixei a noite toda rodando, mais de 8h... Ent√£o vou trocar tudo, at√© a rede padr√£o. S√≥ o 7A ficou bom em algumas dessas. F, G, H e I ficaram bons pro volume e ruim pras outras. F foi a melhor. Ent√£o farei uma h√≠brida.
    - batch (11, "Xo", "Po", "So")
    - batch (24, "Xo", "Po", "So")
    - TODO default => HORR√çVEL ENT√ÉO PULEI PRO PARTE 1
    - TODO parte1
    - TODO parte 2
    - TODO escolhe um √∫nico caso e faz todas as varia√ß√µes de 7 s√≥ pra mostrar que fica boa.
    - TODO comecei fazendo um peda√ßo da parte 3 que deve ficar melhor pra j√° me dar uma ajuda zzzz
  - 1.2) TODO Rede t => V
    - CR (1, 5, "1", "-4"), baixa vaz√£o quase nada
      - Ainda n√£o terminou mas no geral a "7G" parece ser a melhor. C e H tamb√©m ok em alguns pontos.
      TODO 1¬∫ rode os 2 blocos default e 1, depois os 2.coisas
    - CR (1, 5, "25", "-2"), vaz√£o normal
- TODO bota esses 2 testes anteriores j√° na pasta de testes definitivos, acho que rola
- TODO tentar abrir e comprarar MADs no plot 3D. Preciso saber se o modelo do json est√° certo antes de seguir em frente...
2) TODO Para o reator batch testar:
  - Contra todas as loss v7, uns 10 tipos de nondim (j√° inclui t escalado e n√£o escalado...)
  - Nas melhores 3 ou 4 loss testar diferen√ßa de v√°rios LRs e npoints. Isso j√° me diz se faz sentido aumentar ou diminuir ambos.
3) TODO Faz modelos t=>XPSV para CR com varia√ß√£o baixa (4.5L a 5L) porque √© capaz de funcionar e validar. Depois que vou pros de 1 a 5.
4) TODO Faz Modelo batch com hypercube entrando tudo. Esse vai ser bem mais trabalhoso pq vou ter que mexer em cases_to_try, run_reactor e no pinn_saver pra usar as condi√ß√µes. E pode me salvar se o modelo de (3) acabar n√£o prestando.

 -T-O-D-O veja se consegue fazer a generaliza√ß√£o com entrada tipo AllA => (todos os par√¢metros e afins fornecidos como vari√°veis de entrada, menos Xm, Pm)

Coisas que ficaram do dia 7:

LOSSV7 :: TODO veja se s√≥ a loss d2 √© o suficiente pra representar apenas a varia√ß√£o do volume, que √© a mais f√°cil. Se n√£o, pode ter algo errado nos meus c√°lculos. O valor dela √© at√© maior que a d1 e pode ser mais f√°cil o treinamento por d2...

-T-O-D-O-S: 
1) ORGANIZA. TEM COISA DEMAIS, MUITO LERO LERO. BOTA NO ARQUIVO DE TODOS MESMO...
2) Faz um teste tirando o volume da equa√ß√£o de XPS. Ele consegue dar um output OK? Claro que vai estar tecnicamente errado, mas √© s√≥ pra saber se ele sai um volume variando e o xps do batelada simultaneamente
4) Bota uma varia√ß√£o de volume grande 3 executa num intervalo min√∫sculo tipo 0-1h que pare√ßa o batelada. Preciso ver se errei no equacionamento do balan√ßo de volume pelamor
5) Bota artigos numa pasta do zotero pra ler
3) Comece a preparar psicologicamente para ter como entrada todas as vari√°veis (Xo, Po, Vmax, etc). O padr√£o de sa√≠da do reator a gente pode manter da√≠ n√£o precisa de eq. sa√≠da, s√≥ da vaz√£o de entrada mesmo.
-T-O-D-O lembre que ainda ficou tudo pelo meio de ver o pq a adimensionaliza√ß√£o de vari√°veis esculhambava valores e a do tempo n√£o d√° em nada. Isso √© a prioridade pra que eu possa fazer novos testes.
Comece 1) usando a loss v5 pra ver se ainda ficam resultados nada a ver quando usa nondim que n√£o a do tempo. Preciso encontrar o erro zzzz.
Agora tenho que ver as derivadas 1¬™ que n√£o fazem nenhum sentido. As 2 t√£o batendo ok.
Ok testei pro batch a 0.35 do tempo e deu certo nos 3. tem nada errado n√£o zzzz.
2) fuxicando loss v7. Pela ordem, de grandeza j√° sei que a derivada 2 n√£o √© t√£o baixinha a ponto de precisar daquele super acr√©scimo gigantesco de 1e12. Come√ßa por a√≠.


### 2023-10-18
- Posso estar errando a derivada em t=0? Como???
- Tentar loss v7J pra ver se reduz esses picos sem sentido em t pr√≥ximo de zero.
- Nova auto LW ("autic") que recalcula AP√ìS a otimiza√ß√£o inicial
- FEITO testa com esse novo autic
  -  Aten√ß√£o: Agora a loss √© feita com base no p√≥nto mais recente, e n√£o no primeiro. Na pr√°tica, deixou de fazer loss em i=0 e passou a fazer em i=1 para os casos do tipo "auto".
- Meu c√°lculos de dS/dt t√° errado. Como pode dSdt ser constante e a derivada n√£o ser 0, nem no num√©rico???
- Arrumei erro na derivada primeira salva do num√©rico (o valor calculado em si estava certo)
- Testar CR novamente com rede 200x4 e 1200 pontos train e teste. Demora uma vida...
- TODO testa com v7J usando o auto e o autic COM PR√â-TREINO DE ICs
- TODO URGENTE veja o equacionamento e fuxique at√© parar de dar bode. N√£o √© poss√≠vel. Em todos d√° esse pico estranho de S. Parece que o mesmo erro que tinha cometido antes, no num√©rico, cometi no pinn. mas simplesmente N√ÉO CONSIGO EXERGAR ONDE.
  - O problema antes √© que eu tinha que multiplicar a conc. pelo volume antigo e dividir pelo novo. Se n√£o fizesse isso, gerava esse ac√∫mulo infinito. E agora t√° com algo parecido. como proceder ???????? Porque o dSdt era pra ser zerado e acabou. Ser√° que multiplicar o V ao inv√©s de dividir resolve? Acho que n√£o. O que fazer????????????? Multiplicar por dVdt e multiplicar por dt tamb√©m? Isso existe? Tem algumn cabimento?????

### 2023-10-16

 - 1) Pegue os TODOs dos dias anteriores
 - 2) Rode o batch de maior tempo (40h) pra ver se ele tamb√©m apresenta dificuldade em ser resolvido.
  - J√° vi que batch muito tempo ele tamb√©m desanda, ent√£o isso com certeza tamb√©m t√° impactando l√° no cstr. Poderia rodar um tipo 0-10pa s√≥ pra constatar de fato...
  - Teve um que quase prestou em ND-Lin-UPx1-t2-F1d10 de V0-4--Vmax-5--Fin-5E0 em in_t-out_XPSV tr- 0-10pa Glorot uniform-Hammersley. S√≥ o S saiu errado. E usou tudo (nondim, w-Squared e ic 2k)
  - S√ì REACTION  E depois batch sem volume em ts maiores pra validar t nondim.
    - S√£o 40 resultados. Primeiro faz 8x3. Depois 8x6. Depois 30x3. E a√≠ acaba eu acho.
    - Vai validar simultanemante: loss weights e explorar quest√£o do tempo.
      - Ent√£o √© melhor fazer todas as redes ao mesmo tempo, mas separar por nondim, pra ser menos, e aumentar LR pra enviesar menos tb.
      - O caso t6 Upx1 ficou melhor s√≥ com 10h pra predizer as 20 do que a 100%. N√£o acredito que s√≥ a densidade de pontos justificaria isso...
      - Por enquanto o t7 parece ser o melhor de todos, e 0-50pa MUITO melhor que 0-100pa.
  - -X- roda com outros valores de t nondim OK
  - -X- faz CRs t=> V s√≥ pra mostrar que o volume d√° certo.
  - -X- roda um com Xo e Xin = 0. Isso vai acabar com a varia√ß√£o e ele vai precisar predizer basicamente o volume e 2 linhas retas. N√£o √© poss√≠vel.
  - -X- Olha eu poderia t√© continuar tentando, mas esse problema n√£o merce tomar tanto do meu tempo. ganho mais indo terminar de fazer os ajusstes pedidos no trbalho escrito e as novas ilustra√ß√µes. N√£o tem nem cabimento perder tanto tempo nisso. N√£o deu certo e pronto, acabou. Chega de sofrer com isso.

### 2023-10-15

- Parei nos outrs dias porque tava lascado de gripado
- Finalizei redes 3-9x1-6 pra batch tempo normal
-  redes 16-100x1-6 pra batch tempo normal pra LR 1e-3
  - Demorou 207.28 min = 3.45 horas
- Desisti: esse 16-100x1-6 sem nondim, loss weights trocado de "auto-e2-S" pra "A1" (sem weights, =1 pra tudo) e sem o resampler (=None).
  - Eu tenho que fazer beeem menos rede e variar mais params, pq se n√£o a compara√ß√£o √© totalmente injusta.
- Ent√£o vou fazer redes min√∫sculas, 3-6-16 x 3-6.  J√° tenho dados o suficiente pra nondim anterior, agora vou testar outras... Ent√£o fa√ßo as nondim 1 a 1 e vejo quais produzem redes boas mesmo com pouqu√≠ssimos neur√¥nios.
  - Amea√ßou prestar mas desanda f√°ciL: XPSV-8x3 tanh L7B LR-E-4_5 wauto-e2-S Lin-UPx1 p8-32-32 35kep lbfgs-0-1 m-
  - Continua parecendo um problema de sampling, ent√£o deveria investir mais nisso, sinceramente...
- Feito: J√° seria bom eu testar uns CRs com pouca varia√ß√£o de volume. A√≠ pego s√≥ umas 3 tipos de rede, vario um pouco a LR e testo 2 nondim
  - √â, ainda t√° bem ruim. Mesmo com LJ e muitos pontos e resampling n√£o deu conta.
  - Feito: implementar treinar primeiro ICs com adam 2k depois tudo como tava antes. Porque o problema de algumas √© que usa as ICs erradas (loss IC alto) at√© o fim e s√≥ se ajeita no final, assim tamb√©m n√£o d√°.
  - Fiz isso e continuou dando em NADA. Alta densidade de pontos, mais de um tipo de nondim, resampling, treino pr√©vio de ICs. Absolutamente nada resolveu. O volume t√° ok, s√£o as outras que ele t√° indo pra outro ponto de solu√ß√£o, como se fosse (mas sem ser exatamente) uma solu√ß√£o trivial.
  - Ent√£o isso dos pontos muitos j√° posso remover, deu em NADA.
  - mESMO REDE 80X3 TAMB√âM N√ÉO ROLOU
  - O valor de best loss que ele t√° printando sempre √© multiplicando s√≥ os pesos das ICSs, que foram os primeiros a serem usados, mas n√£o tem nada a ver com o exibido pelo gr√°fico que s√£o muito mais altos mds. Os do gr√°fico est√£o certos, √© esse print usando sempre o 1¬∫ LW que t√° totalmente errado.
    - Mentira, t√° certo. √â pq a menor loss, de fato, foi quando treinou s√≥ as ICs.
  - Bom, as redes 30x3 e 80x3 n√£o deram conta ent√£o n√£o √© um problema meramente de mais neur√¥nios. √â uma outra coisa. E que eu n√£o consegui resolver e vai ficar pra pr√≥xima, porque tenho que encerrar esse trabalho.
- A fazer: depois validar novamente resampler e essa estrat√©gia de setar pesos automaticamente


-X- a√≠ esses mesmos testes exatamente os mesmos repito pra sem nondim e pra nondim Lin-Upx1 nas redes 8X. tendo os gr√°ficos erro e Lr e HL pras 3 j√° posso fazer muita conclus√£o.
-X- comece fazendo uma figura explicando as etapas de verifica√ß√£o de como funciona o PINN.
1) Screening => Validar s√≥ XPS do batelada. Ver quest√£o da adimensionaliza√ß√£o, loss weights e10S vs A1 e besteirol afim.
2) Volume constante e variando. Validar modelo e predi√ß√£o. √â t√£o f√°cil que nem compensa comparar formas de adimensionaliza√ß√£o, sinceramente. √â s√≥ pra n√£o questionarem se o volume t√° errado mesmo.
3) Batch XPSV. Foi esse o que fiz por √∫ltimo.

- Terminar esse batch j√° fa√ßa o CR que varia bem pouquinho o volume, pra ver se ao menos ele funciona.


### 2023-10-11

- Obten√ß√£o de v√°rios resultados e ver op√ß√µes do matplotlib pra fazer o gr√°fico. Tlavez seja melhor um heatmap 2D mesmo.


### 2023-10-10

- Talvez a quest√£o sequer seja meramente o CR, mas sim o tempo que passou de X desanda pq chega no pico de m√°ximo. Todos aqueles artigos morrem antes disso e n√£o tem essa inflex√£o de descida...  Ent√£o testar com o batch de 20h...
- Deixe rodando redes do batch pra testar o plot 3D
- NL: (2, 4, 6), (8, 10), 16, 32, 45, 64
- HL: 1-10, grupos: (1-4), (4-7), (8-10) pra maior que 16
- 4 LRs (8e-4, 1e-3, 3e-3, 5e-3,)
=> Como vai ser muito grande, fa√ßa um NL por vez e deixa o resto pronto, s√≥ vai dando comment e uncomment nos NLs
Na sequ√™ncia fazer o plot 3D pra poder conversar com eles... To lerdando muito mesmo trabalhando tanto affff
- Terminei abandonando v√°rios, demorando demaaaais.
- A loss XV3 funcionou em um dos casos mas foi MUITO epec√≠fico, dependeu de LR at√©, uma faixa bem estreitinha.
- Ent√£o farei uma auto loss que roda 1 epoch e dessa 1 epoch tenta tirar a loss de cada ponto e j√° fazer o ajuste autom√°tico.
- FEITO: veja se os n√∫mero ficam != 1, se deu certo... no json de sa√≠da
- J√° tive um resultado com UPx1 que deu aquela zerada ent√£o ele sozinho n√£o resolve n√£o zzz

loss_ajustada = valor desejado
Ex: loss deu 1e-3 mas queria 10. O ajuste multiplicador tem que ser 1e4
Ent√£o √© multiplier = scale_to/loss_firstiteration
loss_adjusted = multiplier*loss_first_iteration. Ent√£o tenho que usar a loss do 
- O auto normal favorece excessivamente quem t√° errado no inicio, podendo esculhambar os outros. Tentar com raiz quadrada ao inv√©s de puro.
- O e-2S t√° MUITO melhor que o e-2, nem se compara. J√° posso usar ele como base.
  Mas terminou sendo super dependente da LR. De toda forma, vou fixar o e-2S e usar ele daqui pra frente.
  - To come√ßando a suspeitar que essa zerada √© uma solu√ß√£o mais f√°cil pras redes com HL e NL muito altos, porque como tem muitos neur√¥nios dispon√≠veis, conseguem fazer eles "desconversarem" e cada um ter mais impacto numa regi√£o espec√≠fica. Nas menores, se alguns deles desandarem pra zerar numa regi√£o pra fazer a zerada, outros podem acabar sendo obrigados a acompanhar pela depend√™ncia.

- Automatizei tudo e vou voltar a fazer de 10 em 10 pq sen√£o ele n aguenta, fica muito lerdo. De lascar.
- Agora que to usando peso de loss adaptado, nem adianta usar a loss pra comparar, vai ter que ser na MAD mesmo ou algo equivalente.
- Fiz teste de sobrescrever json, t√° funcionando bem, n√£o estraga o arquivo.


### 2023-10-09

- Resolvi tirar as adimensionaliza√ß√µes parciais (ex: s√≥ as sa√≠das ou s√≥ as entradas). Adimensionaliza logo tudo. Reduz muito os testes.
- Separar cores em arquivo em utils/colors
- Permitir plotagem de pontos extras por inje√ß√£o de depend√™ncia
- Implementar plotagem dos pontos experimentais automaticamente pro batelada quando condi√ß√µes forem id√™nticas
- parece que n√£o √© nem a quest√£o da varia√ß√£o de volume, mas passar um tempo grande o suficiente pra ter aquela inflex√£o de queda na curva. Tanto √© que o batelada em tempos maiores tamb√©m sofre.
- Change plots default dpi
- mudar cor pontos experimentais
- mudar pontos de treino, tem muitos de bc nem precisa. Uns 4 devem dar conta sinceramente.
- A rede 10x1 parece ter menos problema de zerar o X do que a 10x3, o perfil fica errado mas mais coerente
- Aumentar npoints definitivamente resolveu!!! 10x3 ficou pro s√≥ batch sem volume
  - Acho que j√° poderia tentar fazer em redes menores, tipo 4 e 8 neurons j√° pra produzir gr√°ficos. E reduzir as formas de nondim j√° que todas deram certo com muitos pontos...
  - E tb iterar os npoints pra achar o m√≠nimo necess√°rio pra fazer funcionar...
- parei batelada pra fazer volume variando e ver se consigo botar pra prestar.
- era bom testar mini-batch, porque a√≠ boto muitos pontos mas treino durante um per√≠odo menor, possivelmente
  - **O mini-batch dele nem √© mini-batch de fato, √© um resampler**
  - E 2, n√£o t√° valendo a pena esse monte de pontos. Demora muito mais e os resultados continuam ruins...
  - Francamente, acho que trabalhar com mini-batch (que na verdade √© um resampler!!!!) min√∫sculo pra pegar pontos novos toda itera√ß√£o deve ser uma estrat√©gia melhor do que usar pontos demais.
  - Voltei pra 300p de itera√ß√£o. √â mais seguro do que 32, definitavamente.
  - Upx1 parece que vai ficar melhor que o lin
  - FIXED meu Upx1 t√° errado por algum motivo. N√£o t√° criando o Upx, t√° criando o lin-lin mesmo e n√£o sei o pq.
    - Era um erro na forma de escrever upx1  tava Upx1 no lugar de UPx1 mds.

- Preciso aumentar epochs. V√°rias vezes corto o treino justo quando ia come√ßar a dar certo...
- Terminei criando a 7J, que exclui aquele besteirol de signal que deve atrapalhar muito.
- talvez o que v√° resolver minha vida √© usar uma rede mais complexa, tipo 80x4, como padr√£o, 
- F1x deu Nan no UPx1. Ent√£o j√° posso come√ßar pulando ele.
- Testei F1d100 no UPx1 com esperan√ßa mas tamb√©m pareceu bem p√©ssimo. Pelo visto vou ter que abandonar, foi uma ideia sem futuro.
  - Mas da√≠ aumentei a LR e resolveu, ficou bem melhor zzzz
  - Pois vamos fazer assim: pra t2-F1d100 Lin-UPX1 varia LR e faz uma busca de HL e NL
  - Repete isso pra t2-F1d100 do LinLin
  - OK, t2x10 e F1d100 novamente ficou excelente mesmo no Lin-UPX1. Agora √© bom eu testar o t2x100 s√≥ pra ver se fica ainda melhor. Isso ajuda demais... Mas novamente LR important√≠ssima zzz....
  - Do meio pro fim o melhor foi o t2x10F1d100. Ent√£o vou usar ele pra tudo enquanto acho uma boa...
  - NEssas settings tanto a 7B quanto a 7J deram certo, com a diferen√ßa que a 7B foi MUITO mais r√°pida, ficou um pouquinho pior nos gr√°ficos normais e levemente pior no gr√°fico da derivada segunda.

- O volume √© t√£o bestinha mesmo no CR que uma rede 2x1 deu conta do recado. Ent√£o ele sim pode ser visto pra ver as dificuldades de 7B, 7J e outras formas nondim. Al√©m de ser muito mais r√°pido de rodar.
- A partir de hoje, tudo faz na L7B que √© muito mais r√°pida, depois penso no caso da 7J.


-----------------------------------------

### 2023-10-08 

- !!!!!!! fui muito burro. N√£o podia ter tirado as strings da key porque s√£o elas que garantem que os projetos s√£o √∫nicos e n√£o v√£o se sobrepor. Voltando... em cases_to_try.py
- Talvez a solu√ß√£o seja trocar o dict por uma lista. Mas a ideia do dict era justamente proibir casos iguais usando o nome pra tirar os conflitos automaticamente...
- Trocar estrutura de dict por list. Provavelmente resolver√°.
  - Decidi preservar a estrutura de dict porque ela pro√≠be duplicatas. A√≠ a key e o name s√£o 2 coisas distintas

pinn_saver
  - Corrigido erro: MAD n√£o era exportado
  - Corridigo erro: v√°rias vari√°veis n√£o eram exportadas no json por estarem sendo passadas com ":" e n√£o "="
  - Mas ainda precisei dar clear no cache do python (VSCode => control shift p => clear python cache)
  - add ao json:
    - process_params
    - eq_params
    - altiok params
      - E implementar to_dict em cada respectiva classe
      - FIXED problema ref circular pinn_saver e pinn_results chamando um ao outro
        - Fiz do jeito mais f√°cil e burro, que foi tirar o tipo de pinn_model do pinn_saver e trabalhar "no escuro"

- cases_to_try:
  - atualizar nomenclatura e l√≥gica de pastas, bem como ordem de prepara√ß√£o dos modelos
  - separar em blocos os nondim porque s√£o muitos e ficar comentando/descomentando √© trabalhoso

- Add useMathText to stylesheet
- on "plot_comparer_multiple_grid.py"
  - Apply scilimits (-1, +1) only for axis y
  - Remove previous code for settings the y lims manually (now irrelevant)
- Loss v7 (test: t => V for CR):
  - Loss = Sign of d1 => Resultados p√©ssimos, a loss trava e n√£o consegue mais descer (sendo que se t√° l√° √© porque tem algo errado). talvez eu esteja usando a fun√ß√£o sign de forma errada???
  - Testei loss = (1+sign_dif_d1)*loss_derivative_abs  e  loss = loss_derivative_abs
    - Resultados parecido, mas a loss pareceu reduzir mais r√°pido com o (1+sign_dif_d1)
  - Testando loss = (1) * (loss_derivative_abs + loss_minmax) e loss = (1 + sign_dif_d1) * (loss_derivative_abs + loss_minmax)
    - A deriv + loss_minmax pareceu ser PIOR que a vers√£o sem a loss minmax. Talvez ele esteja com muito "medo" dos valores que ultrapassam os limites e isso esteja atrapalhando.
    - Novamente, os resultados que usaram o signal pareceram melhores
  - Teste rede 10x3:
    - loss = (1 + sign_dif_d1 + sign_dif_d2) * (loss_derivative_abs + loss_minmax + loss_d2) oscilou de 1 a 1.004 e loss = loss_d2 oscilou de 1 a 1.2. Sendo que os valores ficam entre 1 e 1.003. Ent√£o claramente a que tem tudo foi melhor. Agora √© simplificar.
    - loss d1 solo foi pior que loss d2 solo porque fez com que tivesse aquela queda brusca no t imediatamente ap√≥s 0.
    - tudo sem sign foi pior que tudo com sign..

### 2023-10-07

- Loss weight now can be iterated using dictionaries
- Implemented Upscale toNondim and fromNondim, like:
  - N_A = LB + N/N_S
  - N = N_S*(N_A - LB)
  * where N_A = nondimensional "N", N_s = "N" scaler, LB = lower bound, a parameter
- Apagar coment√°rios
-  json solver_params => colocar nondimscaler
- upscale testar se indo e voltando d√° certo
- separar nondim de input e output, agora ser√£o 2. Talvez fique ruim s√≥ pq adimensionalizei o t tb com esses desvios estranhos
- Incluir input e output order no json de sa√≠da
- Estrutura de pasta. O que deve ir pra pasta: 
    1) tipo de reator (j√° tava)
    2) input string/order - output string/order => Pq agrupa por tipo de modelo
    3) range treino
    4) Init function
    5) func. distribuicao treino
    6) func. ativacao
- Agrupamento por pasta
- Remo√ß√£o de convers√£o desnecess√°ria de vari√°veis para numpy arrays
- Botar legendas do lado e n√£o por cima nos gr√°ficos de loss
- arredondar linha cheia da loss plot
- Reorganizar arquivo "main.py" para reaproveitar c√≥digo

Loss v7
- Checar a loss. J√° vi que como tava fazendo antes dNdt_2 calc e predita eram na verdade o mesmo valor, s√≥ tava aumentando o custo computacional. Tenho que fazer as contas certas e comparar corretamente.
  - Realmente, o sinal e a loss da d2 n√£o tavam fazendo nada porque estavam subtraindo o mesmo valor e dando 0. Agora que consertei, elas pioram MUITO a loss... E olha que ainda to no batelada. Termina com loss alta e todo mundo com pregui√ßa de mudar, em 0 ou na condi√ß√£o inicial.
  - 2:34 PM => parece que como montei eu estou incentivando ele a zerar a pr√≥pria derivada segunda, e n√£o a diferen√ßa entre o calculado e o predito...
  - Testar com o batch num tempo maior pra ver o que acontece e comparar as 2...
  - A lerdeza da L7 n√£o √© meramente na loss d2 existir, mas apenas quando ela √© retornada na fra√ß√£o. Ent√£o deve ter algum valor errado, dividindo por zero ou afins que t√° causando essa lerdeza. Possivelmente s√£o erros lan√ßados no background e que o tensorflow v1 n√£o exibe...
  - Veja se s√≥ com o volume variando e sendo predito (in t => out V) ele presta...
    - Loss = loss_deriv1 => deu certo no geral
    - Loss = 
    - Bug no pinn saver: como tem dXdt se a sa√≠da √© s√≥ V??? Resolvido. Eram dXdt e afins do NUM n√£o do PINN. To ficando √© doido.
  - FIXED: Alguns desses gr√°ficos saem tortos por causa da faixa de varia√ß√£o permitida que botei. Da√≠ quando ela √© grande ele corta as bordas, sendo que a ideia era fazer o contr√°rio (que funcionou) de tirar a escala exagerada de varia√ß√µes min√∫culas.
  - Ainda resta um problema: t√° aparecendo 1e5 ao inv√©s de x10¬≤ por exemplo. 
  ref: https://matplotlib.org/stable/gallery/ticks/scalarformatter.html#sphx-glr-gallery-ticks-scalarformatter-py
  O exemplo deles funciona perfeitamente no arquivo main, mas n√£o funcioana dentro da fun√ß√£o de plot em plot_comparer_multiple_grid.py
  - Deleted sciformatter
  - Ok, j√° descobri que √© s√≥ o √∫ltimo plot que n√£o pega essa formata√ß√£o. S√≥ n√£o sei o pq.
    - Achei. Era o plt.yscale, que estava redefinindo as configura√ß√µes do √∫ltimo ax (o de V). N√£o sei o pq e sinceramente n√£o vou atr√°s.
- Atualizar fonte (deixar mais grossinha = mais leg√≠vel)
- Mudar fonte padr√£o
  -  N√£o tava prestando, era o cache que precisei deletar. Fica em user/.matplotlib

2023-10-06 @ 6:47 PM u√© rodei e pareceram OK no batelada at√© com a nondim to ficando √© doido ????

### 2023-10-06

1) aplica tonondim e fromnondim na pr√≥pria rede, como transforma√ß√£o de entrada e sa√≠da, pra n√£o precisar ficar fazendo isso toda hora, s√≥ faz em um √∫nico lugar
  - Arquivo run_reactor => aplicar transforma√ß√£o output e input
  1.1) Output transform
    - 1.1.1) Faz a transformacao pro adimensional
    - 1.1.2) Editar no pr√≥prio ODEPreparer, n√£o ser√° mais necess√°ria a etapa de desadimensionaliza√ß√£o
      - Sem nondim deu o valor certo, t√° OK como esperado (todos os scalers =1)
      - Com nondim tb mds. To come√ßando a suspeitar que essa transform √© apenas no treino, n√£o na rede em si. Isso faz sentido??
      - Se bem que eu n√£o tirei o to e from, ent√£o ele converte 2x e desconverte 2x, e volta pro estado inicial zzzz
      - Eu acho que vou ter que criar mais itens no from e to do nondimscaler: ddt1 e ddt2 (derivadas de 1¬™ e 2¬™ ordem em rela√ß√£o ao tempo, onde somente o tempo est√° adimensionalizado, mas as vari√°veis em si n√£o.)
      - 1¬∫ vou testar usando o from no t, que √© a alternativa mais f√°cil e ver se d√° bode.
      - testar de novo sem nondim OK! Se for sem nondim do tempo. Com o tempo esculhamba tudo. O que fazer?
        - F1d10 com t1 tamb√©m se esculhamba ent√£o n√£o √© bem por a√≠.
        - Enquanto isso t2-1 funcionou bem, ent√£o preciso rever √© a adimensionaliza√ß√£o das vari√°veis !!!!!!
        - Ok, o problema N√ÉO √© na nd do tempo porque s√≥ acontece quando usa a de XPSV ou ambas. Se for s√≥ tempo (t2, t6 ou t7) n√£o d√° errado.
2) pinn_saver
  - Adi√ß√£o de dois novos plots: LoT e LoV das vari√°veis de sa√≠da
  - Novo plot: LoV condi√ß√µes de contorno
  - Corrigido bug que fazia todas as derivadas segundas pra plotagem usando X e n√£o a respectiva vari√°vel de sa√≠da no index.
  - Pronto, deu tudo certo. T√° validado e funcionando pro batelada. Agora posso melhorar a lossv7 sabendo o range de valores com que to trabalhando.


2) testa com o batelada usando uma adimensionaliza√ß√£o bem doida pra ver se sai certo.
Deu certo, ok!

1.1) Acho que eu vou ter que fazer tamb√©m o gr√°fico de derivada segunda
  - Ent√£o seria bom j√° botar isso no Euler e no pinn_saver(img e json MDS)
  - Euler retornar derivadas segundas
  - Os m√©todos de adimensionaliza√ß√£o devem suportar at√© a da derivada 2¬™ ????
  - Pinn saver botar no json
  - Pinn saver processar e salvar imagem
1.2) Bota uma imagem com a loss de cada sa√≠da (XPSV quando houver) ao longo do tempo. Assim eu vejo quem t√° mais desviando zzzz... e uma img separada pras condi√ß√µes iniciais. Ent√£o s√£o +3 imgs.
2.2) Novo teste: variando o volume, mas Cin e Co X != 0 e o resto igual a zero. Quero ver se mant√©m conc. constante.
- 
  - Roda uma batelada pra comparar

### 2023-10-05

*Outra coisa, me pareceu novamente que n√£o √© falta de complexidade da rede n√£o... Algumas 8x ficaram melhores. E redes menores devem ser mais f√°ceis de treinar ent√£o √© melhor eu realmente ir por elas e fazer s√≥ 1 ou 2 grandes pra mostrar que meramente aumentar NL ou HL n√£o resolveria o problema. √â paia mas minha conclus√£o pode ser sim que uma varia√ß√£o grande de volume n√£o p√¥de ser modelada, e a√≠ mostro esse reator simplezinho dando certo.

- Parece que desanda quando aumenta o tempo total, mesmo sem nondim de tempo. N√£o entendi o porqu√™. Mesmo que use o treinamento s√≥ num peda√ßo equivalente ao original. Por exemplo, a rede toda treinada de 0-15pa (~11h) em 72h pro CR que a entrada √© praticamente zero fica bem ruim, mas rodar ele todo em 12h j√° fica bom. Sem sentido total.
  - reactor-V0-1--Vmax-5--Fin-1E-4
    - Para 0-100pa de 12h: F1d100 e F1x10 no geral ficaram ruins e t7F1d10 mostrou bons resultados
    - Para 0-15pa de 72h (~10.8h): ficou bom de novo o t7-F1d10
    - Para 0-100pa de 72h:
  - Hip√≥tese: parte desses problemas de zerar o volume √© pq √© a maneira mais f√°cil de garantir o estado estacion√°rio quando est√° chegando perto, j√° que zera tudo. Eu poderia fazer umas loss v7 que √© igual √† v5, a √∫nica diferen√ßa que d(X,P,S) n√£o multiplica pelo volume e sim divide. E quando o volume for < 0, usar apenas um valor extremamente pequeno como 1e-10

- Refatora√ß√£o do c√≥digo de ODE_PREPARARER: LOSSES
- Implementa√ß√£o e testes da loss v7 (em progresso)
  - FIXED: apenas na loss7 d√° um problema no where
    - Atualizei pra tensorflow 2 e parou. Parece que poderia ser um bug de novo e eu ia passar horas tentando contornar zzzzz.....
    - o Erro no where do V_threshold foi culpa minha, que n√£o havia botado a √∫ltima parte (O "else" do .where)
    - O tensorflow v2 t√° BEM mais demorado que o 1 e emitindo muitos erros, ent√£o vou de volta pra minha terra zzz.
      - No v1 continua com o erro. ent√£o talvez o 2 lerdasse porque t√° tendo um erro que ele resolvia automaticamente mas isso tinha um custo, e o v1 simplesmente joga na minha cara.
      - O erro era que eu tava retornando zero, e n√£o zeroes_like da√≠ dava mismatch no shape
      - No threshold do volume, acontecia algo super parecido. Eu basicamente retornava o threshold, o certo era retornar tf.ones_like(V) vezes o threshold.
        - Comparei resultados lossv7 usando ou n√£o o absoluto como multiplicador quando o sinal da derivada predita e calculada era oposto, e pareceu representar melhor o sistema (loss maior para desvios maiores) E COISA BOA O QUE FOI PRA ZERO, FICOU COM LOSS ALTA (1E1!!!!). Isso √© excelente porque torna a loss uma m√©trica melhor. Mas veja que n√£o foi tanta diferen√ßa assim e d√° uma lerdada no treino viu...
        - Mas a√≠ eu s√≥ to treinando 0-15. Se treinasse os 100%, com a penalidade do erro da dire√ß√£o da derivada, talvez funcionasse, j√° que √© nessa regi√£o que acontece de inverter a subida e a descida...

- Create: Loss Modules

- Voltar pro tensorflow 1 mesmo ok

- Acho que vou ter que mexer na lossv7 mais um pouco ainda... Essa ideia da soma se baseou numa coisa correta (derivadas errasdas) mas n√£o tem sentido pq eu precisaria comparar √© as derivadas segundas!! Porque o sinal das derivadas em si ele n√£o t√° errando tanto.

- Implementar derivadas segundas e testar losses antigas, que n√£o usam. Funcionando OK lossv5 reator batelada, bons resultados.
- Agora sim testar e fazer a loss v7 no reator batelada mesmo pra saber se to fazendo direito
  - Deu certo! Batch ficou OK pra loss com a d2 e pareceu otimizar em menos epochs. Mas falta testar melhor pq foi um √∫nico teste e a 0-15pa de +/-12h n√©...

- Rodei pro batch a nova loss em pontos 64/64/64 e num pedacinho do batch. At√© pra 6 neur√¥nios x2 e x3 ficou bom!!! Isso j√° pode validar essa fun√ß√£o loss nova viu
- Achei um artigo que escreve muito bem e muito resumido, num estilo que posso adotar pra mim. Sobre gPINN.
- O treino com essa nova loss parece ser mais est√°vel, tem muito menos oscila√ß√µes na loss.

TODO faz pro CR esses testes r√°pidos. Talvez me d√™ alguma pista.
TODO fa√ßa a lista que t√° no celular. Novo gr√°fico, de derivadas segundas num√©ricas vs do PINN e botar no json.

### 2023-10-04

- Rede 20NL, lossv5:
  - t2d10-F1d10
    - O sistema que havia funcionado antes foi o de 4.5 a 5L... Por isso. √â ooooutra coisa fi.
    - Perfis semelhantes √† rede 30NL, mas no geral um pouco piores e loss maior (entre 1e-3 e 1e-2, antes ficava entre 1e-4 e 1e-3)
- FIX ME
  - Agora deleta normalmente todos os objetos do keras/tensorflow a cada atualiza√ß√£o (arquivo grid_search.py).
    - ref: [Tensorflow Clear Session](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session)
- Atualizar run_reactor e cases_totry: t range modificado e agora √© s√≥ o PERCENTUAL, n√£o o valor de t j√° multiplicado.
- Rodar agora sim teste relativamente grande, variando camadas, LRs, tudo no mundo, e que me dar√° boas respostas. S√ì N√ÉO PODEREI USAR TEMPO DE TREINO E PREDI√á√ÉO PORQUE ESTOU USANDO O COMPUTADOR ENQUANTO RODA!!!!
  - 1¬∫: Teste com XPS de sa√≠da e t e V de entrada...
  - Realmente N√ÉO consegui determinar o bug dos NaNs nas condi√ß√µes iniciais quando alguma vari√°vel de entrada outra que o tempo √© acionada. Ele alega, indiretamente, que est√° recebendo um tuple ou algo parecido.
- FIX: Encontrei o erro. Quando a geometrica se tornava TimeGeometry, era necess√°rio usar uma classe diferente para DATA, bem como condi√ß√µes de contorno diferentes. Arquivos atualizados: run_reactor, cases_to_try. Tamb√©m modifiquei parte a l√≥gica de determinar o % a ser explorado no treino em rela√ß√£o ao m√°ximo.
- Novo reator padr√£o: reactor-V0-1--Vmax-5--Fin-25E-2
  - Acho que a rede 10x √© o suficiente. Tenho que explorar √© estrat√©gias. Ent√£o fa√ßa nela que vc consegue testar mais coisas.
  - selu n√£o ficou muito legal, nem swish mas n√£o rodei demais. Terminei decidindo rodar s√≥ em 2 LR (1e-3 e 1e-4) pra facilitar minha vida e conseguir fazer mais testes.
  - Fiz testes com 10k adam tb pareceu pouco. Vou apagar e fazer mais com mais pontos.
  - Novos testes zzz.. Se ficarem ruins, nos outros aumentar pra 32 NL porque j√° tive bons resultados com 32x3 e 32x5 no passado.
  - Ainda parecem bem ruins, swish e tanh. Usei nondim tempo mas nos testes antigos todos os nondim tempo tinham ficado ruins. Nos novos tinham uns bons pq n√£o fiz para o reator CR, s√≥ isso e fim. Ent√£o √© melhor eu tentar sem mesmo...
  - Fiz mais e continuam p√©ssimos...


### 2023-10-03

- Novos resultados: (30 NL por padr√£o)
  - reactor-V0-3--Vmax-5--Fin-25E-2
    - t2d5-1
    - t2d10-1
    - t2d100-1
      - ^ Esse foi de longe o pior. Os outros n√£o teve um que foi efetivamente melhor que os demais...
    - t2d10-F1
      - se ficar ruim, talvez eu tenha que fazer na rede 20x de novo mds... Agora pq funciona num e na outra n√£o? 0 sentidos viu
    - t2d10-F1d10
      - A partir desse, inclu√≠ o teste pra LR=1e-2 porque era a usada no original, que tinha dado certo...
      - Esse antigamente tinha dado certo, e motivou essa escolha: ND-Lin-t4-F1d10 in_t out_XPSV tanh tr-0-25pa L5 LR-E-2_1 20x2 p16-32-32 45kep lbfgs-1 TD-Hammersley m-
      - A √∫nica diferen√ßa √© que eram 20 neurons e n√£o 30. Pelo amor...
    - t2-F1d10 S√ì 20 NEURONS X2-3-4
      - N√£o ficou bom. Refazer com t2d10 pra 20NL.
      - opini√£o ????

### 2023-10-02

- Novos resultados (t2x100, etc...)

### 2023-09-29

- Mais testes com varia√ß√£o de nondim  (t2, t2x5, t2x10)

### 2023-09-28

- Cria√ß√£o de modelos t2 x10 x100 x5 e d5 d10 d100;
- Voltei √† loss v5. A v6 √© muito cheia de lero lero e d√° muito trabalho.
- Me parece que ainda assim s√£o MUITO sens√≠veis √† LR... Mesmo com rede 30x3. Talvez fosse bom eu testar em combina√ß√£o com os F1d10 e afins (s√≥ fiz com F1 e os t2 x e d valores). Em progresso porque demora muito. As redes 10x n√£o estavam t√£o boas ent√£o decidir aumentar pra garantir que n√£o fosse por falta de capacidade da rede... Esses testes todos foram s√≥ 0-15pa. Alguns quiseram prestar mas prestar que √© bom nenhum rolou.
- De novo tem uns ok mas desandam depois dos 15% de tempo. Acho bom eu fazer um 0-30pa e da√≠ j√° testar. Pego as redes 10 e 30 x2 e x3 e da√≠ rodo pra v√°rios LR uma ou duas nondims por vez
- Mais testes com redes 30x3 e afins pra NDN t2 e t1. Os outros n√£o consigo fazer hoje, v√£o ficar pra amanh√£. De vez em quando tem uns interessantes, mas francamente nada muito bom.

### 2023-09-26

- Modelos t6F1d10 para CR... testando.

### 2023-09-25

- Novas varia√ß√µes da loss v6
  - Multiplicar loss dVdt por 50 resolveu mas ainda n√£o t√° muito legal.
- Consegui alguns resultados aparentemente aceit√°veis usando t6 e Fd10 com tempo 0-15pa para o CR menorzinho. J√° √© um
- Loss v6: nova itera√ß√£o zzzz... Estava dando default pra loss v5 pra tudo com exce√ß√£o de V, por isso minha modifica√ß√µes n√£o tinham surtido efeito algum.
- Voltar a fazer treinos na regi√£o 0-15pa e ir ajustando a loss na marra com base em hip√≥teses, e s√≥ depois ir pras demais...

### 2023-09-22

- Implementar varia√ß√£o de CRs com params
- Nova l√≥gica para gera√ß√£o da id do modelo
- Testes preliminares com redes min√∫sculas (2-10 neur√¥nios, 1-3 camadas) no CSTR. 0-20 pa mas t√° tudo indo relativamente bem. O problema realmente devem ser nos valores com pico e queda...

### 2023-09-21

- Nos gr√°ficos 3D a escala log √© bugada, ent√£o vou ter que fazer por fora se for o caso. Colocar log_scale faz somente com que exiba os n√∫mero em log (10^-3 etc) mas n√£o vai colocar em escala log de fato...

### 2023-09-20

- Add garbage collector
- Add novo estudo de caso CR: cr-4x5L. O reator inicia em 4.5L e s√≥ vai at√© 5L. Assim consigo ver se numa varia√ß√£o pequena ele ainda teria essa dificuldade que os outros CRs (fora o constante) est√£o apresentando. Deu pra ver que n√£o, ele fica bem tranquilo e d√° tudo certo rapidinho. Isso serviu pra validar o equacionamento...
- Novos testes pros reatores CR. N√£o preciso botar todos mas quero ao menos ver se chego em alguma conclus√£o razo√°vel.
- Pelos meus testes do reator cr-1E-1L o problema n√£o parece ser meramente a profundidade ou neur√¥nios da rede, porque a 80x3 tamb√©m deu na mesma. Realmente acho que √© algo no treino ou na loss, e que talvez eu arrume ainda nas redes 10x. Como t√° demorando MUITO. Acho que vou ter que fazer cada NL, HL e Nondim individualmente por todos os LRs. Se n√£o for assim vai passar de 60 itera√ß√µes, e a partir da√≠ elas s√£o t√£o absurdamente mais lentas que simplesmente n√£o compensa.
  - Olha, pensando bem, eu poderia come√ßar fazer s√≥ 0-10% do tempo de simula√ß√£o, depois 0-20% e indo assim at√© encontrar qual o "t" problem√°tico, se √© onde acontecem os picos...
- Mais testes pro CR. Precisei aumentar adam pochs pra 120k e ainda assim n√£o sei se foi o suficiente. Testei apenas apra t7  FD Lin.

### 2023-09-19

- Novos testes com nondim e redes 30x e 10x. A adimensionaliza√ß√£o das vari√°veis sozinha (F1d10) foi consideravelmente melhor que as outras e que as op√ß√µes sem adimensionaliza√ß√£o.
- Testes nondim t
  - Testes em rede 10x3 adimensionalizando o tempo e XPS
  - Testes em rede 10x3 adimensionalizando apenas o tempo
  - Adimensionaliza√ß√£o t4 parece ser, no geral, pior que as demais (√© a /10)
  - t only
    - t7 ficou bom em 3 faixas de lr bem distintas (1e-2, 1e-3 e 1e-4). Isso √© muito bom.
    - t3 ficou aceit√°vel em 3
    - v√°rios outros ficaram bons em 2 das 3 faixas, incluindo o sem nondim. Eu iria de t7. Mas o valor num√©rico de t7 √© bem pr√≥ximo do t2, ent√£o seja s√≥ uma coincid√™ncia.
- Add param: solver params > is_save => determina se vai salvar ou n√£o o modelo, padr√£o √© falso
- Bug fix: o que foi salvo como dV/dt era na verdade dSdt. S√≥ n√£o deu em nada porque todos os testes at√© agora tinham sido somente a rea√ß√£o, ent√£o n√£o tinha dV/dt para ser salvo. C√≥digo estava em pinn_saver.py.
- Implementar: Agora √© poss√≠vel rodar apenas a predi√ß√£o de volume
- plot_comparer_multiple_grid => Agora seta automaticamente limites superiores e inferiores de y para cropar valores muito pr√≥ximos e evitar aquela nota√ß√£o "+5" no topo, por exemplo, quando os valores variavam entre 4.9999 e 5.00001.

### 2023-09-18

- Finalizar testes redes p/ reaction only
- At√© mesmo a rede 10x2 teve uns casos aceit√°veis. Vou ent√£o fazer o teste variando a LR.
- Criado o arquivo json_viewer, que abre todos os jsons dada uma lista de nomes de arquivos. Da√≠ ele pega as informa√ß√µes marcadas (atrav√©s de um callback para ser chamado por fora) e fecha os arquivos. Assim posso pegar por exemplo todas as √∫ltimas loss dos arquivos X e Y.
- Plot caller e gr√°ficos relacionados + integra√ß√£o com o json_viewer
  - Padroniza√ß√£o do dict para scatter
  - Gr√°fico scatter implementado
  - FIX: Figura era resetada ao girar, o que salvava uma imagem em branco.
  - UPDATE: Mudado o padr√£o do dict passado por argumento do 3d plot.
  - Plot por √¢ngulo funcionando OK
  - 

### 2023-09-17

- Novos testes com LR
- Determina√ß√£o que treino por Hammersley √© bem melhor que distribui√ß√£o uniform. Ver: "results\2023-09 teste preliminares pt2\reaction Altiok\1 hammersley e uniform dif ABSURDA"
- Corrigido: em "grid_search.py" File n√£o estava sendo close() (fechado) o que impactava a performance e esculhambava o arquivo pinns.json
- Testes de NL e LR para rea√ß√£o. Fiz 1/6.

### 2023-09-16

- Corrigido bug no plot da derivada. Era pra ser a derivada normal, e n√£o a adimensional mesmo.
- Cases to try: substitu√≠do forma de declarar nondim scalers.
- Implementa√ß√£o expl√≠cita das condi√ß√µes de adimensionaliza√ß√£o do tempo e demais vari√°veis
- Testes para rea√ß√£o: LR e Epochs
- Testes de LR e Adams. Fazer todos juntos fica invi√°vel pelo tempo eu acho...
- Mais testes de noite (19-22)
  - De 0-60% t na rea√ß√£o only batch fica bem f√°cil de acertar. 0-90 desanda.
  - No gr√°fico: agora plota uma linha indicando o intervalo de treino.
- Criar arquivo "thinking.md"
- Encontrei algumas redes boas em 30x3 para 0-90pa e com t_ND=caso "t2". 
- Pra amanh√£, √© bom ver se consigo desenrolar logo e dar uma olhada nos testes do t nondim...

### 2023-09-15

- Permitir (cases_to_try, grid_search, run_reactor, solver_params json) o uso de tempos min. e m√°ximo do experimento diferentes de 0 e t_max para avaliar isso.
- Fazer o reator batelada num tempo maior como uma configura√ß√£o extra e ver como ele se comporta, se tamb√©m fica com erro alto, etc.
- Daqui pra frente acho que mini batch pode ser totalmente ignorada, vamos trabalhar s√≥ na distribui√ß√£o de pontos e ver o comportamento dali.
- Parece n√£o ser uma solu√ß√£o trivial (do ponto de vista matem√°tico) mas do ponto de vista de ML: zerar X e botar tudo constante era algo que baixava muito o erro sem ter muitas consequ√™ncias. 
- Removi o termo que multiplica a loss minmax  por 10. Como o valor absoluto j√° √© maior que a derivada, multiplicar ele faz com que a derivada fique menos relevante para a composi√ß√£o da loss e talvez isso implique naqueles erros. Al√©m de que ficou mais dif√≠cil o processo de treino.
- Corrigido: plot de derivadas agora √© salvo com o valor adimensional para poder ver a sobreposi√ß√£o independentemente da escala e ficar mais f√°cil de comparar. Foi poss√≠vel ver claramente a predi√ß√£o errando o volume e acertando o resto. Mas a√≠ "acerta" o resto j√° descontando o erro do volume, ent√£o tamb√©m erra!
- No json de pinn => adicionado tamb√©m as predi√ß√µes das derivadas
- Rodar s√≥ a rea√ß√£o com loss v5 contra lossv6 j√° mostra que a 5 √© muito melhor. A 6 hoje, enquanto escrevo isso, √© a mesma coisa que a 4 antiga. Ent√£o isso j√° valida a complexidade de ter um termo ^3.

### 2023-09-14

- Rascunho loss v6 multiplicando o erro<0 por 10 e por 100
- Adicionar valores calculados de d(X,P,S,V)_dt aos resultados num√©ricos
- Plotar por padr√£o, al√©m de XPSV, d(X,P,S,V)_dt num√©rico
- Plotar dXPSV/dt do Pin... E comparar com o num√©rico. J√° vi que est√£o indo em dire√ß√µes opostas no in√≠cio do treino...
- Agora plotar o gr√°fico com t de simula√ß√£o (num√©rico) vs t que foi discretizado (pontos n√£o linhas) Importante pra eu saber se uma regi√£o est√° sendo muito desprivilegiada. Na verdade √© uma linha de t e os pontos por cima pra eu poder comparar


### 2023-09-13

- Testar mais v√°rios valores de loss, todos ruins. Implementei varia√ß√£o de LR. Estou preparando pra testar variar a loss mesmo, de novo zzzz.

### 2023-09-12

- Implement Autosave for each pinn using a callback
  - A 56 pinns simulation failed (OOM - out of memory) so all models were lost. This is to prevent it to happen again.
- Remove plot loss for multiple pinn. Implement individual loss ploting.



### 2023-09-09

- Loss v5 foi modificada, e sem a normaliza√ß√£o autom√°tica. Resultados absurdamente melhores, praticamente todas as redes ficaram boas e com baixa varia√ß√£o, at√© mesmo do volume. Essa vers√£o j√° pode ser a loss final porque acabou de ser validade pro reator batelada.
- Loss v5 validada com batelada.
- CR => Novos modelos definidos no c√≥digo e no arquivo naming.
- Testei distribui√ß√µes e salvei (Hammersley e LHS) mas n√£o parece ser a√≠ o problema
- Mesmo a vers√£o CSTR puro (j√° inicia no volume m√°ximo) fica bem p√©ssimo. O volume at√© prediz ok, o resto desanda. Continua me parecendo que esse pico da fun√ß√£o √© super respons√°vel por isso... O batch j√° validou o equacionamento da rea√ß√£o... Ent√£o isso t√° certo, j√° foi confirmado. Ficou super bom mesmo nessa lossv5.
- Cheguei a testar 4000 pontos teste e domain + mini-batch de 20, continuou bem ruim.
- Um dos testes do CSTR finalmente funcionou bem. NN 16x1 com NDLin escalado a 10.


### 2023-09-08

Loss v5 // loss 5 // lossv5 // loss5 => As losses s√£o normalizadas em 50% da soma para ficarem todas na mesma ordem de grandeza
  - L_n' = 0.8\*L_n + 0.2\*Loss_pde_total
    - Repare que isso torna a Loss total artificalmente maior, ent√£o n√£o d√° pra usar s√≥ ela pra comparar.
- Aumentar resolu√ß√£o dos gr√°ficos dew XPSV e Loss (600 dpi)
- CSTR
  - CSTR Renomeado para cr("continuous_reactor")
  - Implementar novas condi√ß√µes do reator cont√≠nuo
    - X_in e P_in = 0
    - P0 n√£o √© 0 porque considera que foi incubado ent√£o j√° pode ter produzido algo
- Mudar cores loss train x teste em compara√ß√£o com pinn vs euler, n√£o faz sentido serem a mesma
- Ajustar limites dos gr√°ficos pra n√£o ficar aquele 4.99 + 0.0001 

### 2023-09-03

- Escrever novas nondim no documento (OK)

### 2023-09-02

- Erro no tempo do fed-batch. No texto est√° escrito 1036 (um erro porque deveria ser 10.6) porque digitei errado no teclado num√©rico.
- Escrever novas *losses* no documento e nos slides.

### 2023-08-22

- Encontrei um erro s√©rio
  - Ao pegar o reator, sempre convertia como se tivesse adimensionalizado. Mas acontece que o m√©todo num√©rico nunca tava sendo adimensionalizado. I.E. os valores nunca s√£o os nondim, mas os valores absolutos (NO NUM√âRICO). Isso significa que tudo de l√° deve ser convertido para nondim.
- Adicionei o salvamento dos valores calculados numericamente, predi√ß√£o pinn e predi√ß√£o pinn ainda nondim, sem converter. Pro caso de precisar no futuro. N√£o √© poss√≠vel, agora t√° f√°cil de mexer. Pelo amor...

### 2023-08-23
- Novo teste loss v4 + nondim batch: 6. Deu certo. O √∫nico problema √© o volume caindo ao longo do tempo.